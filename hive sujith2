[training@localhost ~]$ hive
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
Hive history file=/tmp/training/hive_job_log_training_202307201553_508523475.txt
hive>  SELECT * , COUNT(*)FROM purchase GROUP BY userID;    
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0006, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0006
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0006
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 15:55:22,418 Stage-1 map = 0%,  reduce = 0%
2023-07-20 15:55:26,473 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.38 sec
2023-07-20 15:55:27,488 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.38 sec
2023-07-20 15:55:28,502 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.38 sec
2023-07-20 15:55:29,515 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.38 sec
2023-07-20 15:55:30,554 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.38 sec
2023-07-20 15:55:31,575 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.6 sec
2023-07-20 15:55:32,597 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.6 sec
2023-07-20 15:55:33,616 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.6 sec
2023-07-20 15:55:34,627 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.6 sec
MapReduce Total cumulative CPU time: 3 seconds 600 msec
Ended Job = job_202307201453_0006
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.6 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 600 msec
OK
1	1	1
2	1	1
3	1	1
4	1	1
5	1	1
Time taken: 22.739 seconds
hive> SELECT AVG(amount) FROM purchase;    
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0007, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0007
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0007
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 15:56:39,936 Stage-1 map = 0%,  reduce = 0%
2023-07-20 15:56:43,972 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 15:56:44,985 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 15:56:45,995 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 15:56:47,005 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 15:56:48,017 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 15:56:49,033 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.19 sec
2023-07-20 15:56:50,047 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.19 sec
2023-07-20 15:56:51,061 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.19 sec
2023-07-20 15:56:52,081 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.19 sec
MapReduce Total cumulative CPU time: 3 seconds 190 msec
Ended Job = job_202307201453_0007
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.19 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 190 msec
OK
130.0
Time taken: 16.867 seconds
hive> SELECT min(amount) FROM purchase;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0008, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0008
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0008
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 15:57:12,073 Stage-1 map = 0%,  reduce = 0%
2023-07-20 15:57:26,270 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:27,283 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:28,294 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:29,319 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:30,349 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:31,385 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:32,417 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:33,446 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2023-07-20 15:57:34,463 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.29 sec
2023-07-20 15:57:35,476 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.29 sec
2023-07-20 15:57:36,489 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.29 sec
2023-07-20 15:57:37,511 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.29 sec
2023-07-20 15:57:38,531 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.29 sec
2023-07-20 15:57:39,553 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.29 sec
2023-07-20 15:57:40,565 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:41,574 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:42,589 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:43,611 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:44,632 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:45,656 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:46,682 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:47,717 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
2023-07-20 15:57:48,741 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.8 sec
MapReduce Total cumulative CPU time: 3 seconds 800 msec
Ended Job = job_202307201453_0008
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.8 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 800 msec
OK
100
Time taken: 41.357 seconds
hive> SELECT MAX(amount) FROM purchase;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0009, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0009
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0009
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 15:59:15,809 Stage-1 map = 0%,  reduce = 0%
2023-07-20 15:59:24,953 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.4 sec
2023-07-20 15:59:25,963 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.4 sec
2023-07-20 15:59:26,972 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.4 sec
2023-07-20 15:59:27,984 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.4 sec
2023-07-20 15:59:29,007 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.4 sec
2023-07-20 15:59:30,019 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.48 sec
2023-07-20 15:59:31,027 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.48 sec
2023-07-20 15:59:32,035 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.48 sec
2023-07-20 15:59:33,042 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.48 sec
MapReduce Total cumulative CPU time: 3 seconds 480 msec
Ended Job = job_202307201453_0009
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.48 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 480 msec
OK
80
Time taken: 21.872 seconds
hive> SELECT MAX(amount) FROM purchase;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0010, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0010
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0010
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 16:00:23,957 Stage-1 map = 0%,  reduce = 0%
2023-07-20 16:00:27,989 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 16:00:28,999 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 16:00:30,012 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 16:00:31,020 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2023-07-20 16:00:32,029 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:33,040 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:34,049 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:35,075 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:36,137 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:37,153 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:38,189 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:39,212 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:40,249 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
2023-07-20 16:00:41,281 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec
MapReduce Total cumulative CPU time: 3 seconds 230 msec
Ended Job = job_202307201453_0010
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.23 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 230 msec
OK
80
Time taken: 21.99 seconds
hive> SELECT SUM(amount) FROM purchase;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0011, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0011
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0011
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 16:01:24,491 Stage-1 map = 0%,  reduce = 0%
2023-07-20 16:01:33,639 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:34,649 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:35,659 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:36,668 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:37,698 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:38,737 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:39,764 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:40,800 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:41,815 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:01:42,842 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.13 sec
2023-07-20 16:01:43,851 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.5 sec
2023-07-20 16:01:44,862 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.5 sec
2023-07-20 16:01:45,891 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.5 sec
2023-07-20 16:01:46,918 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.5 sec
MapReduce Total cumulative CPU time: 3 seconds 500 msec
Ended Job = job_202307201453_0011
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.5 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 500 msec
OK
650.0
Time taken: 27.084 seconds
hive> SELECT * FROM purchase ORDER BY amount DESC;    
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0012, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0012
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0012
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 16:03:10,494 Stage-1 map = 0%,  reduce = 0%
2023-07-20 16:03:19,626 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:20,634 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:21,642 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:22,652 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:23,679 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:24,710 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:25,745 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:26,765 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:27,789 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.19 sec
2023-07-20 16:03:28,816 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.19 sec
2023-07-20 16:03:29,843 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.19 sec
2023-07-20 16:03:30,865 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.19 sec
2023-07-20 16:03:31,904 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.19 sec
2023-07-20 16:03:32,915 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.19 sec
2023-07-20 16:03:33,922 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.68 sec
2023-07-20 16:03:34,930 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.68 sec
2023-07-20 16:03:35,940 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.68 sec
2023-07-20 16:03:36,952 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.68 sec
MapReduce Total cumulative CPU time: 3 seconds 680 msec
Ended Job = job_202307201453_0012
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.68 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 680 msec
OK
5	2023-01-01 10:17:00.0	80
3	2023-01-01 10:09:00.0	200
2	2023-01-01 10:08:00.0	150
4	2023-01-01 10:13:00.0	120
1	2023-01-01 10:05:00.0	100
Time taken: 31.026 seconds
hive> SELECT * FROM purchase ORDER BY amount ACE; 
FAILED: ParseException line 1:39 mismatched input 'ACE' expecting EOF near 'amount'

hive> SELECT * FROM purchase ORDER BY amount ASC;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_202307201453_0013, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0013
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0013
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-07-20 16:04:23,697 Stage-1 map = 0%,  reduce = 0%
2023-07-20 16:04:27,729 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:04:28,738 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:04:29,746 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:04:30,754 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:04:31,765 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2023-07-20 16:04:32,774 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.27 sec
2023-07-20 16:04:33,783 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.27 sec
2023-07-20 16:04:34,794 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.27 sec
2023-07-20 16:04:35,830 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.27 sec
MapReduce Total cumulative CPU time: 3 seconds 270 msec
Ended Job = job_202307201453_0013
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 3.27 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 270 msec
OK
1	2023-01-01 10:05:00.0	100
4	2023-01-01 10:13:00.0	120
2	2023-01-01 10:08:00.0	150
3	2023-01-01 10:09:00.0	200
5	2023-01-01 10:17:00.0	80
Time taken: 16.77 seconds
hive> SELECT * FROM Clicstrem WHERE page IS NULL;      
FAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'Clicstrem'
hive> SELECT * FROM Clickstream WHERE page IS NULL;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_202307201453_0014, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0014
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0014
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2023-07-20 16:07:47,351 Stage-1 map = 0%,  reduce = 0%
2023-07-20 16:07:51,380 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.96 sec
2023-07-20 16:07:52,389 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.96 sec
2023-07-20 16:07:53,397 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.96 sec
2023-07-20 16:07:54,424 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 0.96 sec
MapReduce Total cumulative CPU time: 960 msec
Ended Job = job_202307201453_0014
MapReduce Jobs Launched: 
Job 0: Map: 1   Cumulative CPU: 0.96 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 960 msec
OK
Time taken: 11.686 seconds
hive> SELECT * FROM purchase WHERE amount IS NULL;   
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_202307201453_0015, Tracking URL = http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202307201453_0015
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_202307201453_0015
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2023-07-20 16:09:23,804 Stage-1 map = 0%,  reduce = 0%
2023-07-20 16:09:27,837 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.98 sec
2023-07-20 16:09:28,844 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.98 sec
2023-07-20 16:09:29,852 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.98 sec
2023-07-20 16:09:30,892 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 0.98 sec
MapReduce Total cumulative CPU time: 980 msec
Ended Job = job_202307201453_0015
MapReduce Jobs Launched: 
Job 0: Map: 1   Cumulative CPU: 0.98 sec   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 980 msec
OK
Time taken: 11.668 seconds
hive> 
